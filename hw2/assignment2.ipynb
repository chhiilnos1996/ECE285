{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print('done 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3010e-36, 4.0327e-34, 6.3010e-36],\n",
      "        [6.3010e-36, 6.3010e-36, 6.3010e-36],\n",
      "        [6.3010e-36, 6.3010e-36, 6.6071e-30],\n",
      "        [6.3010e-36, 1.7320e-24, 1.0324e-31],\n",
      "        [6.3010e-36, 6.3010e-36, 6.3010e-36]])\n",
      "<class 'torch.Tensor'>\n",
      "done 1\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)\n",
    "print(type(x))\n",
    "print('done 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.How was x initialized? \n",
    "<br> ans : uniform distribution on the interval [0, 1)\n",
    "<br> 2.What is the type of x? \n",
    "<br> ans : <class 'torch.Tensor'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6615, 0.6132, 0.9607],\n",
      "        [0.1278, 0.9502, 0.9245],\n",
      "        [0.4973, 0.9049, 0.1544],\n",
      "        [0.7344, 0.3393, 0.8382],\n",
      "        [0.8564, 0.1259, 0.9502]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.0225,  1.0487, -1.3311],\n",
      "        [-2.0992, -0.5357, -1.3288],\n",
      "        [-0.3447,  0.8363,  0.3612],\n",
      "        [ 0.7947, -0.3761, -0.2809],\n",
      "        [ 1.8755, -0.3926, -0.2710]])\n",
      "<class 'torch.Tensor'>\n",
      "done 2\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "print(type(y))\n",
    "y = torch.randn(5, 3)\n",
    "print(y)\n",
    "print(type(y))\n",
    "print('done 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How are the random values distributed? \n",
    "<br> ans: uniform distribution on the interval [0, 1)\n",
    "2. What is the type of y?  \n",
    "<br> ans: <class 'torch.Tensor'>\n",
    "3. What if we use instead y = torch.randn(5, 3)?\n",
    "<br> ans: to 1 becomes random numbers from a normal distribution with mean 0 and variance 1(standard normal distribution), \n",
    "    to 2 it's the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3010e-36, 4.0327e-34, 6.3010e-36],\n",
      "        [6.3010e-36, 6.3010e-36, 6.3010e-36],\n",
      "        [6.3010e-36, 6.3010e-36, 6.6071e-30],\n",
      "        [6.3010e-36, 1.7320e-24, 1.0324e-31],\n",
      "        [6.3010e-36, 6.3010e-36, 6.3010e-36]], dtype=torch.float64)\n",
      "tensor([[ 0.0225,  1.0487, -1.3311],\n",
      "        [-2.0992, -0.5357, -1.3288],\n",
      "        [-0.3447,  0.8363,  0.3612],\n",
      "        [ 0.7947, -0.3761, -0.2809],\n",
      "        [ 1.8755, -0.3926, -0.2710]], dtype=torch.float64)\n",
      "done 3\n"
     ]
    }
   ],
   "source": [
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)\n",
    "print('done 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the type displayed when you print x and y?\n",
    "<br> ans: dtype=torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "done 4\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-0.1859, 1.3970, 0.5236],\n",
    "[ 2.3854, 0.0707, 2.1970],\n",
    "[-0.3587, 1.2359, 1.8951],\n",
    "[-0.1189, -0.1376, 0.4647],\n",
    "[-1.8968, 2.0164, 0.1092]])\n",
    "y = torch.Tensor([[ 0.4838, 0.5822, 0.2755],\n",
    "[ 1.0982, 0.4932, -0.6680],\n",
    "[ 0.7915, 0.6580, -0.5819],\n",
    "[ 0.3825, -1.1822, 1.5217],\n",
    "[ 0.6042, -0.2280, 1.3210]])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print('done 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.What are their shapes?\n",
    "<br>ans: both are [5, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([5, 6])\n",
      "done 5\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack((x, y))\n",
    "print(z.shape)\n",
    "z1 = torch.cat((x, y), 0)\n",
    "print(z1.shape)\n",
    "z2 = torch.cat((x, y), 1)\n",
    "print(z2.shape)\n",
    "print('done 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the shape of z?\n",
    "<br> ans: [2, 5, 3]\n",
    "2. How does it compare to torch.cat((x, y), 0) and torch.cat((x, y), 1)?\n",
    "<br> ans: for torch.cat((x, y), 0) the size is [10, 3] (horizontal concatenation) and for torch.cat((x, y), 1) the size is [5, 6] (vertical concatenation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n",
      "tensor(1.3210)\n",
      "tensor(1.3210)\n",
      "tensor(1.3210)\n",
      "done 6\n"
     ]
    }
   ],
   "source": [
    "print(y[4,2])\n",
    "print(z[1,4,2])\n",
    "print(z1[9,2])\n",
    "print(z2[4,5])\n",
    "print('done 6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1859,  1.3970,  0.5236],\n",
      "         [ 2.3854,  0.0707,  2.1970],\n",
      "         [-0.3587,  1.2359,  1.8951],\n",
      "         [-0.1189, -0.1376,  0.4647],\n",
      "         [-1.8968,  2.0164,  0.1092]],\n",
      "\n",
      "        [[ 0.4838,  0.5822,  0.2755],\n",
      "         [ 1.0982,  0.4932, -0.6680],\n",
      "         [ 0.7915,  0.6580, -0.5819],\n",
      "         [ 0.3825, -1.1822,  1.5217],\n",
      "         [ 0.6042, -0.2280,  1.3210]]])\n",
      "tensor(1.3210)\n",
      "done 7\n"
     ]
    }
   ],
   "source": [
    "print(z)\n",
    "print(z[1,4,2])\n",
    "print('done 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "<class 'torch.Tensor'>\n",
      "done 8\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(type(x+y))\n",
    "print(torch.add(x, y))\n",
    "print(type(torch.add(x, y)))\n",
    "print(x.add(y))\n",
    "print(type(x.add(y)))\n",
    "torch.add(x, y, out=x)\n",
    "print(x)\n",
    "print(type(x))\n",
    "print('done 8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Check whether the above instructions are printing the same output? \n",
    "<br>ans: yes.\n",
    "<br>2.Are they equivalent?\n",
    "<br>ans: yes, even their type are the same, so I think the answer is yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "done 9\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "print('done 9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Interpret the effect of each of these instructions. What does the -1 mean?\n",
    "<br> ans : y = x.view(16) means to reshape x into a torch vector of size 16, and z = x.view(-1, 8) means to reshape x into a shape with the second dimension being 8 and -1 is left for pytorch to caculate the dimension for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  6.0103, -10.9136]])\n",
      "done 10\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 10)\n",
    "x = x.view(1,-1)\n",
    "y = torch.randn(2, 100)\n",
    "y = y.view(-1,2)\n",
    "z = torch.mm(x, y)\n",
    "print(z)\n",
    "print('done 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<class 'torch.Tensor'>\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "done 11\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))\n",
    "print('done 11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.What are the types of a and b?\n",
    "<br>ans: types of a is torch.Tensor, types of b is numpy.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n",
      "done 12\n"
     ]
    }
   ],
   "source": [
    "a[0] +=1\n",
    "print(a)\n",
    "print(b)\n",
    "print('done 12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do they match? Do they share their underlying memory locations?\n",
    "<br>ans: yes! they match! this means that they share the same memory location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 2., 2., 2., 2.])\n",
      "[3. 2. 2. 2. 2.]\n",
      "tensor([4., 3., 3., 3., 3.])\n",
      "[4. 3. 3. 3. 3.]\n",
      "tensor([5., 4., 4., 4., 4.])\n",
      "[4. 3. 3. 3. 3.]\n",
      "done 13\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "a[:] += 1\n",
    "print(a)\n",
    "print(b)\n",
    "a = a.add(1)\n",
    "print(a)\n",
    "print(b)\n",
    "print('done 13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.What are the similarities and differences?\n",
    "<br>ans: the first to add on the memory of a, so that both a and b are changed, the third have a copy of a and add to the copy, and then assign back to a so b is not changed, only a is changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "done 14\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)\n",
    "print('done 14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1.903615951538086\n",
      "tensor([[ 0.7350, -0.9255,  0.6547],\n",
      "        [ 0.2325,  0.3528, -1.6503],\n",
      "        [-0.6904, -0.2882, -0.7547],\n",
      "        [-0.2944,  2.0928, -0.3064],\n",
      "        [ 0.0832, -1.3315,  0.5129]], device='cuda:0')\n",
      "0.4291200041770935\n",
      "tensor([[ 0.1645,  0.4576, -0.5774],\n",
      "        [-0.9119, -0.3864, -1.5767],\n",
      "        [ 1.0437,  0.0614,  1.0957],\n",
      "        [-0.0369, -0.9374,  0.1452],\n",
      "        [-1.3395, -0.2864, -0.3556]], device='cuda:0')\n",
      "0.33792001008987427\n",
      "tensor([[ 0.8995, -0.4679,  0.0773],\n",
      "        [-0.6794, -0.0336, -3.2270],\n",
      "        [ 0.3532, -0.2268,  0.3410],\n",
      "        [-0.3313,  1.1554, -0.1612],\n",
      "        [-1.2563, -1.6179,  0.1573]], device='cuda:0')\n",
      "done 15\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# Waits for everything to finish running\n",
    "start.record()\n",
    "x = torch.randn(5, 3).to(device)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(start.elapsed_time(end))\n",
    "print(x)\n",
    "\n",
    "start.record()\n",
    "y = torch.randn(5, 3, device=device)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(start.elapsed_time(end))\n",
    "print(y)\n",
    "\n",
    "start.record()\n",
    "z = x + y\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(start.elapsed_time(end))\n",
    "print(z)\n",
    "print('done 15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Interpret each of these instructions. Compare the two allocation instructions for x and y, which one\n",
    "is the most efficient? \n",
    "<br>ans: The first one creates a torch cpu tensor and then move to cuda device, the second one create a tensor directly on gpu so the second one is almost three times faster than the first. And z = x + y create a tensor of value x+y on cuda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89949304 -0.46792105  0.07727093]\n",
      " [-0.67940265 -0.0336017  -3.2270107 ]\n",
      " [ 0.3532496  -0.22676757  0.34098345]\n",
      " [-0.33133048  1.155433   -0.1611959 ]\n",
      " [-1.2562898  -1.6178792   0.15734383]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-598b4aabeb92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done 16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())\n",
    "print('done 16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if z is in cpu we can call numpy directly, if not we have to detach first to call numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "True\n",
      "None\n",
      "None\n",
      "done 17\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.requires_grad)\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print('done 17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the requires grad attribute of y? \n",
    "<br> ans: True\n",
    "2. What are the grad attributes of x and y?\n",
    "<br> ans: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "done 18\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "f = z.mean()\n",
    "print(z, f)\n",
    "print('done 18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x_1,x_2,x_3,x_4) = \\frac{(x_1+2)(x_1+2)+(x_2+2)(x_3+2)+(x_1+2)(x_2+2)+(x_2+2)(x_4+2)+(x_3+2)(x_1+2)+(x_4+2)(x_3+2)+(x_3+2)(x_2+2)+(x_4+2)(x_4+2)}{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 19\n"
     ]
    }
   ],
   "source": [
    "f.backward() # That's it!\n",
    "print('done 19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial f(x_1,x_2,x_3,x_4)}{\\partial x_1} = \\frac{\\partial f(x_1,x_2,x_3,x_4)}{\\partial x_1}$\n",
    "$= \\frac{2*x_1+4+x_2+2+x_3+2}{4} = \\frac{x_1}{2}+\\frac{x_2}{4}+\\frac{x_3}{4}+2$\n",
    "<br>others are similar\n",
    "<br>done 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 21\n"
     ]
    }
   ],
   "source": [
    "import MNISTtools\n",
    "import numpy as np\n",
    "def normalize_MNIST_images(x):\n",
    "    y = x\n",
    "    y.astype(np.float32)\n",
    "    y = y*2/255 -1\n",
    "    return y\n",
    "xtrain, ltrain = MNISTtools.load(dataset=\"training\", path=\"/datasets/MNIST/\")\n",
    "xtest, ltest = MNISTtools.load(dataset=\"testing\", path=\"/datasets/MNIST/\")\n",
    "xtrain_normalized = normalize_MNIST_images(xtrain)\n",
    "xtest_normalized = normalize_MNIST_images(xtest)\n",
    "print('done 21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1, 60000)\n",
      "(28, 28, 1, 10000)\n",
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n",
      "done 22\n"
     ]
    }
   ],
   "source": [
    "xtrain_normalized = np.reshape(xtrain_normalized, (28,28,1,60000))\n",
    "xtest_normalized = np.reshape(xtest_normalized, (28,28,1,10000))\n",
    "print(xtrain_normalized.shape)\n",
    "print(xtest_normalized.shape)\n",
    "xtrain_normalized = np.moveaxis(xtrain_normalized, [0,1,2,3], [2,3,1,0])\n",
    "xtest_normalized = np.moveaxis(xtest_normalized, [0,1,2,3], [2,3,1,0])\n",
    "print(xtrain_normalized.shape)\n",
    "print(xtest_normalized.shape)\n",
    "print('done 22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 23\n"
     ]
    }
   ],
   "source": [
    "MNISTtools.show(xtrain_normalized[42, 0, :, :])\n",
    "print('done 23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the digit 7 corresponds to ltrain[42]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "done 24\n"
     ]
    }
   ],
   "source": [
    "xtrain_normalized = torch.from_numpy(xtrain_normalized)\n",
    "xtest_normalized = torch.from_numpy(xtest_normalized)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "ltest = torch.from_numpy(ltest)\n",
    "print(type(xtrain_normalized))\n",
    "print(type(xtest_normalized))\n",
    "print(type(ltrain))\n",
    "print(type(ltest))\n",
    "print('done 24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Determine the size of the feature maps after each convolution and maxpooling operation i.e. atpoints (i)-(iv) processing steps. How many input units does the third layer have ie. input at (v)?\n",
    "<br>(i) feature maps size [24,24]\n",
    "<br>(ii) feature maps size [12,12]\n",
    "<br>(iii) feature maps size [8,8]\n",
    "<br>(iv) feature maps size [4,4]\n",
    "<br>(v) 84 input units\n",
    "<br>print('done 25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "done 26\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "net = LeNet()\n",
    "print(net)\n",
    "print('done 26')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the learnable parameters? \n",
    "<br> ans : conv1.weight, conv1.bias, conv2.weight, conv2.bias, \n",
    "<br> fc1.weight, fc1.bias, fc2.weight, fc2.bias, fc3.weight, fc3.bias.\n",
    "2. Are gradients going to be tracked by autograd for all parameters?\n",
    "<br> ans : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.float64\n",
      "tensor(11.3500)\n"
     ]
    }
   ],
   "source": [
    "print(type(xtest_normalized))\n",
    "print(xtest_normalized.dtype)\n",
    "xtest_normalized = xtest_normalized.float()\n",
    "with torch.no_grad():\n",
    "    yinit = net(xtest_normalized)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge with 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N =  60000\n",
      "NB =  600\n",
      "T =  3\n",
      "epoch =  0\n",
      "k =  0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f6807043d3dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mxtrain_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtrain_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mbackprop_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mltrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-f6807043d3dd>\u001b[0m in \u001b[0;36mbackprop_deep\u001b[0;34m(xtrain, ltrain, net, T, B, gamma, rho)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# Error evaluation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         raise RuntimeError(\n\u001b[1;32m    177\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T=3, B=100, gamma=.001, rho=.9):\n",
    "        N = xtrain.size()[0] # Training set size\n",
    "        print('N = ',N)\n",
    "        NB = np.ceil(N/B) # Number of minibatches\n",
    "        NB = NB.astype(int)\n",
    "        print('NB = ',NB)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "        print('T = ',T)\n",
    "        for epoch in range(T):\n",
    "            print('epoch = ',epoch)\n",
    "            running_loss = 0.0\n",
    "            shuffled_indices = np.random.permutation(range(xtrain.size()[0]))\n",
    "            for k in range(NB):\n",
    "                print('k = ',k)\n",
    "                # Extract k-th minibatch from xtrain and ltrain\n",
    "                minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "                inputs = xtrain[minibatch_indices]\n",
    "                labels = ltrain[minibatch_indices]\n",
    "                # Initialize the gradients to zero\n",
    "                optimizer.zero_grad()\n",
    "                # Forward propagation\n",
    "                outputs = net(inputs)\n",
    "                # Error evaluation)\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Back propagation\n",
    "                backprop_deep(xtrain_normalized[minibatch_indices], labels, net)\n",
    "                # Parameter update\n",
    "                optimizer.step()\n",
    "                # Print averaged loss per minibatch every 100 mini-batches\n",
    "                # Compute and print statistics\n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item()\n",
    "                if k % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %(epoch + 1, k + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "                \n",
    "net = LeNet()\n",
    "xtrain_normalized = xtrain_normalized.float()\n",
    "backprop_deep(xtrain_normalized, ltrain, net, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b6b0ce9ed2d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0myinit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myinit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mltest\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest_normalized)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N =  60000\n",
      "NB =  600\n",
      "T =  10\n",
      "epoch =  0\n",
      "k =  0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a735718916e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mxtrain_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtrain_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mbackprop_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mltrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-a735718916e3>\u001b[0m in \u001b[0;36mbackprop_deep\u001b[0;34m(xtrain, ltrain, net, T, B, gamma, rho)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# Error evaluation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         raise RuntimeError(\n\u001b[1;32m    177\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "\n",
    "def backprop_deep(xtrain, ltrain, net, T=3, B=100, gamma=.001, rho=.9):\n",
    "        N = xtrain.size()[0] # Training set size\n",
    "        print('N = ',N)\n",
    "        NB = np.ceil(N/B) # Number of minibatches\n",
    "        NB = NB.astype(int)\n",
    "        print('NB = ',NB)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "        print('T = ',T)\n",
    "        for epoch in range(T):\n",
    "            print('epoch = ',epoch)\n",
    "            running_loss = 0.0\n",
    "            shuffled_indices = np.random.permutation(range(xtrain.size()[0]))\n",
    "            for k in range(NB):\n",
    "                print('k = ',k)\n",
    "                # Extract k-th minibatch from xtrain and ltrain\n",
    "                minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "                inputs = xtrain[minibatch_indices]\n",
    "                labels = ltrain[minibatch_indices]\n",
    "                # Initialize the gradients to zero\n",
    "                optimizer.zero_grad()\n",
    "                # Forward propagation\n",
    "                outputs = net(inputs)\n",
    "                # Error evaluation)\n",
    "                outputs = outputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Back propagation\n",
    "                backprop_deep(xtrain_normalized[minibatch_indices], labels, net)\n",
    "                # Parameter update\n",
    "                optimizer.step()\n",
    "                # Print averaged loss per minibatch every 100 mini-batches\n",
    "                # Compute and print statistics\n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item()\n",
    "                if k % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %(epoch + 1, k + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "net = LeNet().to(device)                 \n",
    "xtrain_normalized = xtrain_normalized.float()\n",
    "backprop_deep(xtrain_normalized, ltrain, net, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9100)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest_normalized)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
